# BuriedBrains: A Roguelike-Inspired Single-Agent RL Environment

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) ## üìú Vis√£o Geral

**BuriedBrains** √© um ambiente de simula√ß√£o procedural, parcialmente observ√°vel (POMDP) e de alto risco, projetado como um benchmark para pesquisa em Aprendizado por Refor√ßo (RL), com foco no estudo de agentes com mem√≥ria e na emerg√™ncia de comportamentos complexos. Inspirado em jogos do g√™nero roguelike, o ambiente utiliza mec√¢nicas como morte permanente (`permadeath`) e gera√ß√£o procedural de n√≠veis para criar cen√°rios desafiadores que exigem planejamento estrat√©gico, gerenciamento de risco e adapta√ß√£o sob incerteza.

Esta vers√£o do reposit√≥rio (`buriedbrains-roguelike-sae`) foca na **Parte 1** do projeto: o **Ambiente Single-Agent PvE (Player versus Environment)**. O objetivo desta fase √© validar o core do ambiente, testar a capacidade de aprendizado de agentes RL (PPO, LSTM) e investigar a necessidade de mem√≥ria em um POMDP complexo.

## üéÆ Inspira√ß√£o

O projeto **BuriedBrains** foi inspirado diretamente no jogo mobile *Buriedbornes*, desenvolvido pela Nussygame. Este jogo combina elementos cl√°ssicos de roguelikes com combate t√°tico por turnos, progress√£o baseada em risco e morte permanente ‚Äî caracter√≠sticas que influenciaram fortemente o design do ambiente. A simplicidade visual aliada √† profundidade estrat√©gica de *Buriedbornes* serviu como base conceitual para criar um ambiente de RL desafiador, parcialmente observ√°vel e com gera√ß√£o procedural, ideal para investigar agentes com mem√≥ria e tomada de decis√£o sob incerteza.

Este projeto foi desenvolvido como parte de um Trabalho de Conclus√£o de Curso (TCC) em Engenharia da Computa√ß√£o na Universidade Federal do Cear√° (UFC) - Campus Sobral.

## ‚ú® Funcionalidades Principais (Parte 1 - PvE)

* **Ambiente Gymnasium-Compat√≠vel:** Interface padr√£o para f√°cil integra√ß√£o com frameworks de RL como Stable Baselines3.
* **Gera√ß√£o Procedural Baseada em Grafos:** Os n√≠veis (andares de progress√£o) s√£o modelados como Grafos Ac√≠clicos Dirigidos (DAGs) gerados dinamicamente, com poda de ramos n√£o escolhidos.
* **Parcial Observabilidade (POMDP):** O agente possui uma vis√£o limitada do ambiente, necessitando de mem√≥ria ou infer√™ncia para tomar decis√µes √≥timas.
* **Combate T√°tico:** Sistema de combate por turnos com habilidades, cooldowns, efeitos de status e gerenciamento de HP.
* **Progress√£o e Risco:** Mec√¢nica de morte permanente (`permadeath`) e sistema de n√≠veis/experi√™ncia.
* **Conte√∫do Configur√°vel via YAML:** Inimigos, habilidades, equipamentos, eventos e efeitos de sala s√£o definidos em arquivos YAML, permitindo f√°cil balanceamento e extens√£o.
* **Gera√ß√£o de Conte√∫do Baseada em Budget:** A dificuldade e variedade das salas s√£o controladas por um sistema de "or√ßamento" e regras condicionais.
* **Logging Detalhado e Hall da Fama:** Callback customizado para Stable Baselines3 que registra m√©tricas detalhadas e salva os logs completos das runs mais bem-sucedidas.

## üéØ Motiva√ß√£o e Objetivos

O objetivo central desta fase do BuriedBrains √© fornecer um benchmark robusto para investigar quest√µes fundamentais em IA:

* **Necessidade de Mem√≥ria:** Testar experimentalmente como a capacidade de mem√≥ria (e.g., LSTM) impacta o desempenho em ambientes POMDP com desafios sequenciais e mec√¢nicas complexas (Hip√≥tese H1).
* **Tomada de Decis√£o sob Risco:** Analisar como a mec√¢nica de `permadeath` influencia o desenvolvimento de estrat√©gias prudentes versus agressivas (Hip√≥tese H2).
* **Generaliza√ß√£o:** Avaliar se os agentes aprendem pol√≠ticas generaliz√°veis que funcionam em n√≠veis gerados proceduralmente, em vez de memorizar solu√ß√µes espec√≠ficas (Hip√≥tese H4).

## üìä Status Atual e Resultados Principais

* O ambiente PvE single-agent est√° funcional e passou por v√°rios ciclos de balanceamento.
* Experimentos comparando PPO (sem mem√≥ria) e RecurrentPPO (LSTM) demonstraram que, **no ambiente atual com chefes e mec√¢nicas complexas, a mem√≥ria (LSTM) √© crucial para o aprendizado e a sobreviv√™ncia**, validando a Hip√≥tese H1 para este cen√°rio.
* O agente LSTM √© capaz de aprender pol√≠ticas para sobreviver e progredir no ambiente, embora a dura√ß√£o longa dos combates contra chefes seja um gargalo para completar o jogo consistentemente dentro do limite de tempo padr√£o (30k passos).

## üõ†Ô∏è Arquitetura e Tecnologias

* **Linguagem:** Python 3.x
* **Core RL:** Gymnasium, Stable Baselines3
* **Computa√ß√£o Num√©rica:** NumPy, PyTorch (via Stable Baselines3)
* **Grafos:** NetworkX (para modelagem e manipula√ß√£o da topologia)
* **Configura√ß√£o:** PyYAML

## üöÄ Instala√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/maelsilvatt/buriedbrains-roguelike-rl-env.git](https://github.com/maelsilvatt/buriedbrains-roguelike-rl-env.git)
    cd buriedbrains-roguelike-rl-env
    ```
2.  **Crie um ambiente virtual (recomendado):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Linux/macOS
    # ou
    .\venv\Scripts\activate  # Windows
    ```
3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

## ‚ñ∂Ô∏è Uso (Treinamento)

O script principal para treinar um agente √© `train.py`. Ele aceita argumentos de linha de comando para configurar o experimento:

```bash
python train.py [op√ß√µes]
````

**Op√ß√µes Principais:**

  * `--no_lstm`: Usa PPO padr√£o (MlpPolicy) em vez de RecurrentPPO (MlpLstmPolicy).
  * `--total_timesteps <int>`: N√∫mero total de passos de treinamento (padr√£o: 5,000,000).
  * `--max_episode_steps <int>`: Limite de passos por epis√≥dio no ambiente (padr√£o: 30,000).
  * `--budget_multiplier <float>`: Multiplicador de dificuldade (padr√£o: 1.0). Afeta o "or√ßamento" para gera√ß√£o de conte√∫do.
  * `--suffix <str>`: Adiciona um sufixo customizado ao nome da pasta de log/modelo.

**Exemplos:**

  * **Treinar LSTM (padr√£o) por 1M de passos:**
    ```bash
    python train.py --total_timesteps 1000000 --suffix "LSTM_Test_1M"
    ```
  * **Treinar PPO (sem LSTM) por 5M de passos com limite de 50k por epis√≥dio:**
    ```bash
    python train.py --no_lstm --total_timesteps 5000000 --max_episode_steps 50000 --suffix "PPO_Baseline_5M_50kSteps"
    ```

Os logs do TensorBoard ser√£o salvos na pasta `logs/` e os modelos e Hall da Fama na subpasta correspondente dentro de `models/` e `logs/`.

## üîÆ Trabalhos Futuros

Embora este reposit√≥rio foque na Parte 1 (PvE), o design completo do BuriedBrains prev√™ uma **Parte 2** focada em intera√ß√µes **Multiagente (MAE)** e **Comportamento Social Emergente**:

  * Implementa√ß√£o das "Zonas K" com topologia de grafo n√£o-direcionado para encontros PvP.
  * Introdu√ß√£o de a√ß√µes sociais (e.g., Soltar/Pegar Artefato para barganha inferida).
  * Implementa√ß√£o do sistema de Karma para rastrear reputa√ß√£o e influenciar intera√ß√µes.
  * Refatora√ß√£o do ambiente para a API multiagente.
  * Desenvolvimento de um loop de treinamento MARL (provavelmente Self-Play)
  * Valida√ß√£o da Hip√≥tese sobre a emerg√™ncia de comportamentos sociais contextuais.
  * Desenvolvimento completo do Visualizador externo em Unity.

## üìÑ Cita√ß√£o

Se usar este ambiente em sua pesquisa, por favor, cite o trabalho
```bibtex
@misc{silva2025buriedbrains,
  author = {Silva, Ismael Soares da},
  title = {BuriedBrains: BuriedBrains: Um Ambiente Roguelike Parcialmente Observ√°vel para Benchmark de Agentes RL com Mem√≥ria},
  year = {2025},
  howpublished = {Trabalho de Conclus√£o de Curso (Engenharia da Computa√ß√£o), Universidade Federal do Cear√°, Campus Sobral},
  note = {Orientador: Prof. Dr. Thiago Iachiley Ara√∫jo de Souza}
}
```

## ‚öñÔ∏è Licen√ßa

Este projeto √© licenciado sob a Licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

```